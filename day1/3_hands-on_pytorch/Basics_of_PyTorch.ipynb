{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Arif Ozan Kızıldağ*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWA4heDjVPXV"
   },
   "source": [
    "This tutorial will introduce you to the basics of PyTorch while we tackle a news classification task using the AG NEWS dataset. While creating this tutorial, we utilized the [``Text classification with the torchtext library``](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html) tutorial from the official PyTorch tutorials as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPCAHXIJ6Sn6"
   },
   "source": [
    "PyTorch is a Python deep learning library from Facebook mainly written with CUDA, which is a general-purpose GPU computing framework of NVIDIA. Its low-level design is intended to be similar to Numpy and to follow Python principles as much as possible. It facilitates deep learning applications with its CUDA backend, automatic differentiation mechanism on computational graphs, and its utilities for machine learning and deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJaCgY0b6CDo",
    "outputId": "6e52183e-94d0-416a-b942-d40f4d092105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version of the torch:2.0.1\n",
      "version of the torchtext:0.15.2\n",
      "version of the torchdata:0.6.1\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torchtext\n",
    "import torchdata\n",
    "%matplotlib inline\n",
    "print('version of the torch:' + torch.__version__)\n",
    "print('version of the torchtext:' + torchtext.__version__)\n",
    "print('version of the torchdata:' + torchdata.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZ_Y441F915v"
   },
   "source": [
    "PyTorch supports the CUDA backend for accelerating parallelizable operations such as matrix multiplication and convolution in GPU. You can check if CUDA is available in the current session by calling `torch.cuda.is_avaliable()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "To2VUhVOAPdq",
    "outputId": "30d6ec13-f773-4820-c96c-ee16ffa8ff36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPsKb7EG6q68"
   },
   "source": [
    "## Tensors and Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jgZYsgx61K0"
   },
   "source": [
    "With PyTorch, you can create tensors in the way that you create arrays in Numpy. `torch.Tensor` is the main data structure of PyTorch. It holds the necessary information for the computation of created computational graphs in both forward and backward modes. Each tensor is an edge in computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5onkpAx460HD",
    "outputId": "a5a91970-80f5-4dc7-f1fa-807ecd916db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTensor generated with zeros method:\u001b[0m\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\u001b[1m\n",
      "Tensor generated with ones method:\u001b[0m\n",
      "tensor([[2.5000, 2.5000, 2.5000],\n",
      "        [2.5000, 2.5000, 2.5000],\n",
      "        [2.5000, 2.5000, 2.5000],\n",
      "        [2.5000, 2.5000, 2.5000],\n",
      "        [2.5000, 2.5000, 2.5000]])\n",
      "\u001b[1m\n",
      "Randomly generated tensor:\u001b[0m\n",
      "tensor([[0.2983, 0.4563, 0.9009],\n",
      "        [0.3079, 0.5502, 0.3269],\n",
      "        [0.6809, 0.4641, 0.1907],\n",
      "        [0.9260, 0.7665, 0.1745],\n",
      "        [0.3402, 0.9769, 0.3311]])\n"
     ]
    }
   ],
   "source": [
    "# Basic data operations\n",
    "x1 = torch.zeros(5, 3) # You can initialize tensors with zeros, ones, or rand methods\n",
    "x2 = torch.ones(5, 3) * 2.5  #example of ones method\n",
    "x3 = torch.rand(5, 3)  # example of rand method\n",
    "print('\\033[1m'+'Tensor generated with zeros method:'+'\\033[0m')\n",
    "print(x1)\n",
    "print('\\033[1m'+'\\nTensor generated with ones method:'+'\\033[0m')\n",
    "print(x2)\n",
    "print('\\033[1m'+'\\nRandomly generated tensor:'+'\\033[0m')\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8BASZfg7a3S"
   },
   "source": [
    "Also, you can apply mathematical operations on tensors just as in other scientific computing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erpC4gQk7OJI",
    "outputId": "dd01761a-4f64-4e63-c679-51c7a579b719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSum of x2 and x3:\u001b[0m\n",
      "tensor([[2.7983, 2.9563, 3.4009],\n",
      "        [2.8079, 3.0502, 2.8269],\n",
      "        [3.1809, 2.9641, 2.6907],\n",
      "        [3.4260, 3.2665, 2.6745],\n",
      "        [2.8402, 3.4769, 2.8311]])\n",
      "\u001b[1m\n",
      "Transpose of x3:\u001b[0m\n",
      "tensor([[0.2983, 0.3079, 0.6809, 0.9260, 0.3402],\n",
      "        [0.4563, 0.5502, 0.4641, 0.7665, 0.9769],\n",
      "        [0.9009, 0.3269, 0.1907, 0.1745, 0.3311]])\n",
      "\u001b[1m\n",
      "Shape of x2\u001b[0m\n",
      "torch.Size([5, 3])\n",
      "\u001b[1m\n",
      "Shape of x3.T \u001b[0m\n",
      "torch.Size([3, 5])\n",
      "\u001b[1m\n",
      "Matrix multiplication of x2 and x3.T\u001b[0m\n",
      "tensor([[4.1387, 2.9624, 3.3394, 4.6675, 4.1206],\n",
      "        [4.1387, 2.9624, 3.3394, 4.6675, 4.1206],\n",
      "        [4.1387, 2.9624, 3.3394, 4.6675, 4.1206],\n",
      "        [4.1387, 2.9624, 3.3394, 4.6675, 4.1206],\n",
      "        [4.1387, 2.9624, 3.3394, 4.6675, 4.1206]])\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m'+'Sum of x2 and x3:'+'\\033[0m')\n",
    "print(x2 + x3)\n",
    "print('\\033[1m'+'\\nTranspose of x3:'+'\\033[0m')\n",
    "print(x3.T)\n",
    "print('\\033[1m'+'\\nShape of x2'+'\\033[0m')\n",
    "print(x2.shape)    #shape method of the Tensor return dimentions of the tensor\n",
    "print('\\033[1m'+'\\nShape of x3.T '+'\\033[0m')\n",
    "print(x3.T.shape)\n",
    "print('\\033[1m'+'\\nMatrix multiplication of x2 and x3.T'+'\\033[0m')\n",
    "print(x2 @ x3.T) # @ is matrix multiplication operator. You can use .matmul() method as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QudUL58X9GoJ"
   },
   "source": [
    "PyTorch autograd module lets you take derivatives of the leaf nodes in computational graphs by calling the `.backward()` method of the scalar tensor to be differentiated. In this example, the derivative of `x` with respect to `out = mean(x + y)` is computed by autograd. Note that differentiation by a matrix (or tensor) is nothing but differentiating by all elements in the matrix.\r\n",
    "\r\n",
    "By default, PyTorch does not keep gradients of newly created tensos, unless you specify it when creating a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgHikPfuRsdF",
    "outputId": "6f334691-b730-4891-93b1-44d3c7a8257f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, requires_grad=True)\n",
    "y = torch.ones(2, 3, requires_grad=True) * 0.5\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7tP5YlwSSTK"
   },
   "source": [
    "PyTorch also keeps track of the operations that create tensors to apply chain rule at backward propagation. For example, y is created by a multiplication while x is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtQYN6A_SYaw",
    "outputId": "15c3b5c0-e6b2-4e31-ba59-634d3c0c53ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeM7r8KeSdIP",
    "outputId": "95ecc4c7-c5ef-41ea-e689-d1d7a079e343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-gdGEhpSi31",
    "outputId": "1d0f0468-cce2-4df6-f9ac-f8025b034766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_scalar = z.mean()\n",
    "print(out_scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rfb2UXGT3KT"
   },
   "source": [
    "When you call `.backward()` of a 'scalar valued' tensor, autograd module automatically populates the `.grad` fields of the other tensors in computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdcPA5pKTxrZ",
    "outputId": "5e1d3765-aae3-4581-d362-e3565e9db63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1667, 0.1667, 0.1667],\n",
      "        [0.1667, 0.1667, 0.1667]])\n"
     ]
    }
   ],
   "source": [
    "out_scalar.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A3TjXOuAdsZ"
   },
   "source": [
    "## GPU vs CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_3_YrrUAdQg"
   },
   "source": [
    "You can send tensors in GPU memory by calling `.cuda()` methods from tensors. If you run an operations on tensors in the GPU memory, it will automatically be calculated in GPU so that you don't need to use CUDA for most operations.\n",
    "\n",
    "Here is a benchmark for multiplication of large matrices in CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2wg7p41Arph",
    "outputId": "9c09e570-5218-4318-b568-fbe42bfc4434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61 seconds\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(500, 700)\n",
    "y = torch.rand(700, 900)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for n in range(5000):# depending on the system CPU, this process may take some time\n",
    "    x.matmul(y)\n",
    "\n",
    "end = time()\n",
    "\n",
    "cpu_time = end - start\n",
    "print(f'{cpu_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5RjMMDaAvyQ",
    "outputId": "da956ebc-f3b8-417e-d36b-86881913c8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72 seconds\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(500, 700).cuda()\n",
    "y = torch.rand(700, 900).cuda()\n",
    "\n",
    "start = time()\n",
    "\n",
    "for n in range(5000):\n",
    "    x.matmul(y)\n",
    "\n",
    "end = time()\n",
    "\n",
    "gpu_time = end - start\n",
    "print(f'{gpu_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txvj4AgGA8ag"
   },
   "source": [
    "GPU had a significant advantage here. Actually, this is not even a very significant difference compared to how it speeds up deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ydeZvm3A-37"
   },
   "source": [
    "## Data Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKQtPE_SBNSb"
   },
   "source": [
    "In addition to the scientific computing features of PyTorch, it has utilities for common operations in machine learning. These include dataset operations like sampling, shuffling, batching of data, or loading of commonly used datasets. Some of these features are provided with the `torchtext` library, which is an NLP-specialized library that is officially supported by the PyTorch team.  In this example, the AG_NEWS dataset is loaded using `torchtext.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4ibLhgAWBJ0H"
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "train_iter = iter(AG_NEWS(split='train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92RdgOzvCxXx"
   },
   "source": [
    "This iterator facilitates the efficient processing of raw data and provides easy access to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gfiwnQSDInL",
    "outputId": "41d87ea5-01fe-41eb-9c5b-6823f4c324f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7-pe_KQDpgX"
   },
   "source": [
    "\"In the standard NLP process, we convert text into tokens, which in our context are essentially words. These tokens are then mapped to numbers. \" This can be observed in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xdcYoMCeDpCH"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "train_iter = AG_NEWS(split=\"train\")\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])  # Creates a dictionary for tokens\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfifoGgwEQkO",
    "outputId": "8778cef2-ed29-4d8c-edd7-07043da466cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 30, 5297]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EUgiQS-zE2kj"
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))   # Pipelines for conversion\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yNDGqLZFBsz"
   },
   "source": [
    "The Data Loader in PyTorch efficiently batches and loads datasets for neural network training and evaluation. It supports data shuffling, automatic batching, and parallel data loading with multiple worker processes.\r\n",
    "\r\n",
    "Before sending to the model, the ``collate_fn`` function works on a batch of samples generated from ``DataLoader``. The input to ``collate_fn`` is a batch of data with the batch size in ``DataLoader``, and ``collate_fn`` processes them according to the data processing pipelines declared previously. Pay attention here and make sure that ``collate_fn`` is declared as a top-level def. This ensures that the function is available to each worker.\r\n",
    "\r\n",
    "In this example, the text entries in the original data batch input are packed into a list and concatenated as a single tensor for the input of ``nn.EmbeddingBag``. The offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor. The label is a tensor saving the labels of individual text entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8CtdfGT8Eqe0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "\n",
    "train_iter = AG_NEWS(split=\"train\")\n",
    "dataloader = DataLoader(\n",
    "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIIb_4bxHeDR"
   },
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2WvkesxIkue"
   },
   "source": [
    "To create neural networks with PyTorch, you need to create a Class that inherits `torch.nn.Module`. Then, you need to define the layers in the `__init__` method and define the forward propagation logic in the `forward` method. This class can be considered as a blueprint of the network. It specifies the shapes of its parameters but does not initialize the parameters. The example below shows a 3-layer network with input size 30 and layer sizes [20, 15, 1], respectively. The most common layers are provided by the `torch.nn` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HkUnczrNHfJh"
   },
   "outputs": [],
   "source": [
    "class DumbNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(30, 20)\n",
    "        self.layer2 = torch.nn.Linear(20, 15)\n",
    "        self.layer3 = torch.nn.Linear(15, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yaLNQiTLIu3N"
   },
   "outputs": [],
   "source": [
    "input_data = torch.randn(16, 30) #dummy input to match the network's input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPpD6JD5IyND",
    "outputId": "d7b6494b-821f-4791-936f-7cbb81c08350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 30])\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq2zJ_RLOhNj"
   },
   "source": [
    "To initialize and instantiate a network from the blueprint, you can use the class initialization syntax of Python, which is shown below.\r\n",
    "Note that if the `__init__` method takes arguments other than `self`, then you need to initialize the network with these arguments.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "M8NmylK5OhNk"
   },
   "outputs": [],
   "source": [
    "network = DumbNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im1xVcvZOhNl",
    "outputId": "cccb8716-1f15-4619-ac15-5762e83ef997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DumbNetwork(\n",
      "  (layer1): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (layer2): Linear(in_features=20, out_features=15, bias=True)\n",
      "  (layer3): Linear(in_features=15, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfaG_fgIOhNm"
   },
   "source": [
    "When the network is called via function call operator `()`, the `forward` method of the network is called. Note that the network handles inputs as batches and the batch dimension can be arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Gi8ZNv4xOhNn"
   },
   "outputs": [],
   "source": [
    "output = network(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnvWNqYTOhNo",
    "outputId": "67506a75-e763-4cf3-8fc6-a69a51ad02df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGVEKVW-JGP4"
   },
   "source": [
    "### Lets Create Model for Processing AG_NEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6YiJTQ3JuNp"
   },
   "source": [
    "Now that we know how to create models, let's create models for our task. As mentioned, we are going to utilize an \"embedding bag,\" which is essentially a summation of embeddings. If you're unfamiliar with what embeddings are, you can think of them as representing objects in a multi-dimensional space rather than listing them in a linear array. For example, you could represent the computer you're using in terms of its coordinates (x, y, z) relative to the center of the room.\r\n",
    "\r\n",
    "Text embeddings work similarly; instead of representing each word with a simple number, we represent them in different, abstract dimensions that capture various semantic attributes or ideas.\r\n",
    "\r\n",
    "You have **five minutes** to fill in the empty spaces and make the following class functional. You can verify the accuracy of your work using the next code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc =         ## fill here\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded =  ## fill here\n",
    "        out =   ## fill here\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EniC9jMJy4m"
   },
   "source": [
    "The ``AG_NEWS`` dataset has four labels and therefore the number of classes is four.\r\n",
    "\r\n",
    "1.  World\r\n",
    "2.  Sports\r\n",
    "3.  Business\r\n",
    "4.  Sci/Tec\r\n",
    "\r\n",
    "Let us select the embedding size as 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMNSM6dzJ3at",
    "outputId": "eeeb3dcf-fc02-47c0-d0e3-a926183eeff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassificationModel(\n",
      "  (embedding): EmbeddingBag(95811, 64, mode='mean')\n",
      "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_iter = AG_NEWS(split=\"train\")\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Spoilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MtrcV47JJQuG"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)  ## remove here\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets) ## remvoe here\n",
    "        out = self.fc(embedded)  # remove here\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2xtbpdmQC3Y"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaoG3m5VTJAT"
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iWFGhnpM36k"
   },
   "source": [
    "Since most deep neural networks are trained with a Stochastic Gradient Descent (SGD) variant, PyTorch also has a module that provides most deep learning optimizers, and utilities like learning rate schedulers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Ufwhz3UA0tc0"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(100.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xUIv3SXX0tc4"
   },
   "outputs": [],
   "source": [
    "y = torch.tensor(100.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ydKuiVZ20tc6"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=[x, y],\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjzqzg2DN7xD"
   },
   "source": [
    "Before proceeding, I suggest you to find values of `x` and `y` to minimize `my_function(x, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "B1yX1aL20tc9"
   },
   "outputs": [],
   "source": [
    "def my_function(x, y):\n",
    "    return torch.square(x) + torch.square(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0Bje6g8OAXz"
   },
   "source": [
    "You can create optimizers by initializing the classes in `torch.optim` module with the parameters (needs to be iterable like a list) to be optimized such as learning rate and momentum.\r\n",
    "Actually, optimizers does not know anything about the optimized quantity. It can only access (and reset) the gradient fields (`.grad`) of the tensors in its `params=` argument.\r\n",
    "\r\n",
    "The `grad` field of tensors is populated by the `.backward()` method of to-be-minimized tensor.\r\n",
    "\r\n",
    "In this example, `x` and `y` are optimized to minimize `z` tensor. So `.backward()` needs to be called from`z`.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "U1yIVm0ROGBz"
   },
   "outputs": [],
   "source": [
    "#This optimizer is going to optimize x and y\n",
    "optimizer = torch.optim.SGD(params=[x, y],\n",
    "                            lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9iGaY_1OJYR"
   },
   "source": [
    "Now, try to run the cell below multiple times to see how the SGD optimizer minimizes z by subtracting the gradients of x and y from themselves after multiplying gradients by the learning rate (lr).\r\n",
    "\r\n",
    "You can run cells before proceeding to the next cell by Ctrl+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tt3UbT8q0tdD",
    "outputId": "92308a95-569c-4a4b-d021-2b80e168bcc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x before step is: 100.0\n",
      "y before step is: 100.0\n",
      "gradient of x is: 200.0\n",
      "gradient of y is: 200.0\n",
      "x^2 + y^2 = 20000.0\n"
     ]
    }
   ],
   "source": [
    "#calculate x^2 + y^2\n",
    "z = my_function(x, y)\n",
    "\n",
    "print(f'x before step is: {x.item()}')\n",
    "print(f'y before step is: {y.item()}')\n",
    "#calculate gradients of x and y wrt. z\n",
    "optimizer.zero_grad()\n",
    "z.backward()\n",
    "\n",
    "print(f'gradient of x is: {x.grad.item()}')\n",
    "print(f'gradient of y is: {y.grad.item()}')\n",
    "\n",
    "#take a gradient descent step\n",
    "optimizer.step()\n",
    "\n",
    "print(f'x^2 + y^2 = {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mNNwzlAS_Jb"
   },
   "source": [
    "### Spliting the data and preparing for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2RHCvlRSlHP"
   },
   "source": [
    "Since the original ``AG_NEWS`` has no valid dataset, we split the training\r\n",
    "dataset into train/valid sets with a split ratio of 0.95 (train) and\r\n",
    "0.05 (valid). Here we use\r\n",
    "[torch.utils.data.dataset.random_split](https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split)_\r\n",
    "function in PyTorch core library.\r\n",
    "\r\n",
    "[CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss)_\r\n",
    "criterion combines ``nn.LogSoftmax()`` and ``nn.NLLLoss()`` in a single class.\r\n",
    "It is useful when training a classification problem with C classes.\r\n",
    "[SGD](https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html)_\r\n",
    "implements the stochastic gradient descent method as the optimizer. The initial\r\n",
    "learning rate is set to 5.0.\r\n",
    "[StepLR](https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR)_\r\n",
    "is used here to adjust the learning rate though epochs.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_2X0IBohSizi"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10  # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64  # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = random_split(\n",
    "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USlGkrG-Rmdr"
   },
   "source": [
    "### Lets create optimization loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6cmRPUPSSa5"
   },
   "source": [
    "Let us fill in the missing parts of the training loop. Then run the next code block to test your code and train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "k3fIPvijuRsO"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        ##########################\n",
    "        #call zero_grad, the model (with text and offset) and the calculate the gradients\n",
    "        \n",
    "        predicted_label =\n",
    "        loss = \n",
    "        \n",
    "        ############\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) ## To prevent expoding gradient\n",
    "        ############\n",
    "        ## call optimizer step function\n",
    "        ############\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3ydxz4hR0mg"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWvS-O5fuRsO",
    "outputId": "5ac10b92-195d-4945-a922-9828dd36ee1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 1782 batches | accuracy    0.685\n",
      "| epoch   1 |  1000/ 1782 batches | accuracy    0.849\n",
      "| epoch   1 |  1500/ 1782 batches | accuracy    0.879\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  6.84s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 1782 batches | accuracy    0.898\n",
      "| epoch   2 |  1000/ 1782 batches | accuracy    0.902\n",
      "| epoch   2 |  1500/ 1782 batches | accuracy    0.901\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  6.82s | valid accuracy    0.903 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 1782 batches | accuracy    0.915\n",
      "| epoch   3 |  1000/ 1782 batches | accuracy    0.912\n",
      "| epoch   3 |  1500/ 1782 batches | accuracy    0.915\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.99s | valid accuracy    0.905 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 1782 batches | accuracy    0.925\n",
      "| epoch   4 |  1000/ 1782 batches | accuracy    0.922\n",
      "| epoch   4 |  1500/ 1782 batches | accuracy    0.923\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  6.83s | valid accuracy    0.897 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 1782 batches | accuracy    0.935\n",
      "| epoch   5 |  1000/ 1782 batches | accuracy    0.939\n",
      "| epoch   5 |  1500/ 1782 batches | accuracy    0.937\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  6.88s | valid accuracy    0.912 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 1782 batches | accuracy    0.939\n",
      "| epoch   6 |  1000/ 1782 batches | accuracy    0.938\n",
      "| epoch   6 |  1500/ 1782 batches | accuracy    0.938\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  6.85s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 1782 batches | accuracy    0.940\n",
      "| epoch   7 |  1000/ 1782 batches | accuracy    0.938\n",
      "| epoch   7 |  1500/ 1782 batches | accuracy    0.939\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  6.87s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 1782 batches | accuracy    0.942\n",
      "| epoch   8 |  1000/ 1782 batches | accuracy    0.941\n",
      "| epoch   8 |  1500/ 1782 batches | accuracy    0.940\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  6.79s | valid accuracy    0.912 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 1782 batches | accuracy    0.943\n",
      "| epoch   9 |  1000/ 1782 batches | accuracy    0.942\n",
      "| epoch   9 |  1500/ 1782 batches | accuracy    0.941\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  6.86s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 1782 batches | accuracy    0.941\n",
      "| epoch  10 |  1000/ 1782 batches | accuracy    0.942\n",
      "| epoch  10 |  1500/ 1782 batches | accuracy    0.944\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  6.87s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Spoilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        ##########################\n",
    "        #call zero_grad, the model (with text and offset) and the calculate the gradients\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        ############\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) ## To prevent expoding gradient\n",
    "        ############\n",
    "        ## call optimizer step function\n",
    "        optimizer.step()\n",
    "        ############\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bme6SkyfuRsP"
   },
   "source": [
    "Checking the results of the test dataset…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GIlgeQkuRsP",
    "outputId": "95a7dbca-2d44-4f98-f3c5-d2db2b23f95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.909\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking the results of test dataset.\")\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSUYoSDkuRsP"
   },
   "source": [
    "Use the best model so far and test a golf news.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sg3OjuipuRsP",
    "outputId": "0694a3da-0a29-46d3-9c96-9c3b4356523d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news\n"
     ]
    }
   ],
   "source": [
    "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
    "\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s news\" % ag_news_label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous lessons, we explored NLP using transformer models. Now, let's pivot to the realm of computer vision. We'll work with the classic MNIST dataset, which consists of handwritten digit images. Instead of dealing with the hassle of downloading and preprocessing the dataset manually, we'll leverage the convenience of the torchvision library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a simple neural network module with two layers. This network will have a hidden dimension of 500. Remember to incorporate the ReLU activation function between the two layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleNN(28*28, 500, 10).to(device)\n",
    "print(model)\n",
    "model(torch.rand(10,784).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### @Spoilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN(28*28, 500, 10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [300/938], Loss: 0.5572\n",
      "Epoch [1/5], Step [600/938], Loss: 0.2961\n",
      "Epoch [1/5], Step [900/938], Loss: 0.2194\n",
      "Epoch [2/5], Step [300/938], Loss: 0.0729\n",
      "Epoch [2/5], Step [600/938], Loss: 0.1057\n",
      "Epoch [2/5], Step [900/938], Loss: 0.0985\n",
      "Epoch [3/5], Step [300/938], Loss: 0.4766\n",
      "Epoch [3/5], Step [600/938], Loss: 0.1331\n",
      "Epoch [3/5], Step [900/938], Loss: 0.0943\n",
      "Epoch [4/5], Step [300/938], Loss: 0.0733\n",
      "Epoch [4/5], Step [600/938], Loss: 0.0594\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0346\n",
      "Epoch [5/5], Step [300/938], Loss: 0.1152\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0254\n",
      "Epoch [5/5], Step [900/938], Loss: 0.1785\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 300 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 97.42%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNodkapWkcQjCEjnWwxODiT",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
